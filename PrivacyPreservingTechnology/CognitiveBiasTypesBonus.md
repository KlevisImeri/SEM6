# Cognitive Biases in Dark Patterns

### Choice Overload
***Definition:***
- Too many options lead to decision paralysis.

***Individual effects***
- Decision fatigue ⟹ `Accept All`
- Anxiety and avoidance ⟹ `Accept All`

***Dark Pattern Example***
- Overwhelming privacy settings with 50+ toggles, nudging users to click "Accept All."

***Privacy Implication:***
- Users surrender granular control over data sharing due to complexity.
- Platforms often design cookie consent interfaces to emphasize complexity (e.g., burying options in nested menus, using vague labels like “Partners” instead of clear company names).

***Regulation:***
- In the EU, the `GDPR` and `ePrivacy Directive` require consent to be freely given, specific, and informed. Dark patterns that manipulate choice overload may violate these rules. 
- For example:
    - The French Data Protection Authority (CNIL) fined Google €150 million in 2022 for making it harder to reject cookies than accept them.
    - `Reject/Manage` button: Grayed-out, hidden behind multiple steps, or requiring manual deselection of dozens of toggles.

***Refences:***
- The Decision Lab. (n.d.). Choice Overload Bias. The Decision Lab. Retrieved March 6, 2025, from https://thedecisionlab.com/biases/choice-overload-bias
- Chernev, A., Böckenholt, U., & Goodman, J. K. (2015). Choice overload: A conceptual review and meta-analysis. Journal of Consumer Psychology, 25(2), 333–358. https://chernev.com/wp-content/uploads/2017/02/ChoiceOverload_JCP_2015.pdf
- Commission Nationale de l'Informatique et des Libertés (CNIL). (n.d.). Closure of the injunction issued against Google. https://www.cnil.fr/en/closure-injunction-issued-against-google
- Habib, H., Li, M., Young, E., & Cranor, L. (2022). "Okay, whatever": An evaluation of cookie consent interfaces. Proceedings of the ACM on Human-Computer Interaction, 6(CSCW2), Article 357. https://doi.org/10.1145/3491102.3501985

### Curse of Knowledge
Definition: Designers assume users understand jargon or processes.
Dark Pattern Example: Using technical terms like "third-party data synergies" instead of plain language in consent forms.
Privacy Implication: Users unknowingly permit data sharing due to opaque explanations.

### Scarcity Bias
Definition: People perceive scarce items as more valuable, leading to urgency-driven decisions.
Dark Pattern Example: Displaying "Only 2 left!" or "30 people viewing this" to pressure users into quick purchases.
Privacy Implication: Users might hastily agree to data-sharing terms to secure a "limited-time" offer without reviewing privacy policies.

### Halo Effect
Definition: Positive traits in one area influence perception in unrelated areas.
Dark Pattern Example: A sleek, professional interface masking coercive practices (e.g., hidden subscription fees).
Privacy Implication: Users trust platforms with polished designs, overlooking vague or exploitative privacy terms.

### Sunk Cost Fallacy
Definition: People continue investing in a decision based on prior investments (time/money).
Dark Pattern Example: Free trials requiring credit card details upfront, making users reluctant to cancel after the trial (to avoid "wasting" the setup effort).
Privacy Implication: Users retain subscriptions with invasive data practices to justify their initial commitment.

### Authority Bias
Definition: People trust perceived authorities or experts.
Dark Pattern Example: Fake security badges ("NSA-Approved Encryption") or celebrity endorsements to legitimize excessive data collection.
Privacy Implication: Users share sensitive information under false pretenses of authority-backed safety.

### Reciprocity Bias
Definition: People feel obligated to return favors.
Dark Pattern Example: Offering a "free" eBook in exchange for email sign-ups, later spamming users with promotional content.
Privacy Implication: Users provide personal data to reciprocate a "gift," enabling invasive marketing.

### Status Quo Bias
Definition: People prefer maintaining current decisions.
Dark Pattern Example: Auto-renewing subscriptions with buried cancellation steps.
Privacy Implication: Users retain services with poor data practices due to inertia.

### Social Proof
Definition: People mimic others’ actions to conform.
Dark Pattern Example: "Join 10M+ users who shared their contacts!" to normalize invasive permissions.
Privacy Implication: Users grant unnecessary access (e.g., contacts) to avoid feeling "left out."
